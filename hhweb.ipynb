{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HHWeb\n",
    "\n",
    "A network graph of rap artists' associations by shared phrases. These shared phrases could come about as a result of paying homage, intertextual allusion, or simple plagiarism.  Outside the realm of modern intellectual property, this is a common an well accepted practice in blues music, a genre where rap music has deep roots. \n",
    "\n",
    "I listen to a lot of rap music, and I've noticed this popping up.  It seemed like a fun way to jump into NLP. Really, something about juxtaposing AAVE and technical/academic language just tickles me.\n",
    "\n",
    "This project will show directionality of borrowed phrases, inferred by release date, and cluster artist around influential artists with the most sampled/borrowed phrases.\n",
    "\n",
    "The length of a phrase will be proportional to number of times it appear in order for it to be significant.  This means that a short phrase must be highly unique to count as a link (to ensure it is not simply a common part of speech), while longer phrases can be shared, as their probability of _not_ being attributable is much less."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run this after you have the scraped corpus (hhweb_scraper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import networkx as nx\n",
    "import time\n",
    "import random\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import traceback\n",
    "from difflib import SequenceMatcher\n",
    "import pickle # TODO move this to the top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NGRAM_LEN = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is just for testing, before I pull in the corpus\n",
    "# big_ego = \"Artist: Dr. Dre f/ Hitman Album: The Chronic 2001 Song: Big Ego's Typed by: OHHLA Webmaster DJ Flash [Dr. Dre] I got mo' class than most of em, ran wit the best of em Forgave the less of em, and blazed at the rest of em What can I say? Cal-i-for-ni-A Where niggaz die everyday over some shit they say Disconnected from the streets forever As long as I got a baretta, nigga, I'm down for whateva I roll wit my shit off safety - for niggaz that been hatin me lately and the bitches that wanna break me If Cali blew up, I'd be in the Aftermath Bumpin gangsta rap shit, down to blast for cash Cause from Eazy-E, to D.O.C., to D.P.G. started from that S.O.B., D.R.E. Like Dub-C I'm rich rollin, pistol holdin Pockets swoll nigga, that's how I'm rollin Put the flame to the killer nigga Worldwide homicide mob figure and a builder, for real I'm hittin switches, makin bitches eat bitches See me grab my dick everytime I pose for pictures I own acres, floor seats watchin The Lakers I'm cool with eses who got AK's in cases Dedicated to all of those with big ego's Never fakin, we get the dough and live legal Haters hate this, we sip the Mo' and yank the heezos 1 - Niggaz play this in they Rovers Jeeps and Regals 2 - Bitches play this in they Benzes Jeeps and Geos {repeat 2X} [Hitman] I bust a Mr. Toughy, slash a Smoothy Doobie Crash and flex on Tuesday's, harassin hoes at movies Passin by with uzis - and who you aimin at? That shady bitch and that bitch nigga that was claimin that Rat-ta-tat-tat {*automatic gunfire and screaming*} {*more screaming as tires peel out*} I don't sympathize for wack hoes and wimpy guys You got to recognize Hitman is a enterprise Cali pride, born to ride and South Centralized The Henny got me energized - smoke the guys tryin to focus on mines - poke they eyes out I'm L.A.'s loc'est - hope they don't have to find out the hard way like snitch niggaz in the pen that get hit when the guards look the other way We hittin HARD, Hitman and Dre You playin games, I suggest you know the rules We puttin guns to fools, make you run yo' jewels Take yo' honey and cruise to the snootiest snooze, Cabos Pop coochie til the nut oozes, you shouldn't fuck wit crews that's sick, Aftermath cause we rule shit I'm Big Hit, don't confuse me wit no other by the flow motherfucker Dedicated to all of those with big ego's Never fakin, we get the dough and live legal Haters hate this, we sip the Mo' and yank the heezos 1 - Niggaz play this in they Rovers Jeeps and Regals 2 - Bitches play this in they Benzes Jeeps and Geos {repeat 2X}\"\n",
    "# tribe = \"[Hook: Q-Tip] Can I kick it? (Yes, you can!) Can I kick it? (Yes, you can!) Can I kick it? (Yes, you can!) Can I kick it? (Yes, you can!) Can I kick it? (Yes, you can!) Can I kick it? (Yes, you can!) Can I kick it? (Yes, you can!) Well, I'm gone (Go on then!) [Verse 1: Q-Tip] Can I kick it? To all the people who can Quest like A Tribe does Before this, did you really know what live was? Comprehend to the track, for it's why cuz Gettin measures on the tip of the vibers Rock and roll to the beat of the funk fuzz Wipe your feet really good on the rhythm rug If you feel the urge to freak, do the jitterbug Come and spread your arms if you really need a hug Afrocentric living is a big shrug A life filled with fun that's what I love A lower plateau is what we're above If you diss us, we won't even think of Will Nipper the doggy give a big shove? This rhythm really fits like a snug glove Like a box of positives it's a plus, love As the Tribe flies high like a dove (Can I kick it?) [Hook: Phife Dawg] Can I kick it? (Yes, you can!) Can I kick it? (Yes, you can!) Can I kick it? (Yes, you can!) Can I kick it? (Yes, you can!) Can I kick it? (Yes, you can!) Can I kick it? (Yes, you can!) Can I kick it? (Yes, you can!) Well, I'm gone (Go on then!) [Verse 2: Phife Dawg] Can I kick it? To my Tribe that flows in layers Right now, Phife is a poem sayer At times, I'm a studio conveyor Mr. Dinkins, would you please be my mayor? You'll be doing us a really big favor Boy this track really has a lot of flavor When it comes to rhythms, Quest is your savior Follow us for the funky behavior Make a note on the rhythm we gave ya Feel free, drop your pants, check your ha-ir Do you like the garments that we wear? I instruct you to be the obeyer A rhythm recipe that you'll savor Doesn't matter if you're minor or major Yes, the Tribe of the game we're a player As you inhale like a breath of fresh air (Can I kick it?)\"\n",
    "# sage = \"Can I kick it? (yes you can) [x3] Well I'm gone (go on then) Can I kick it, to all my people who get wicked like Sage does before this did you know what my real name was Paul Francis acting like he's on the same drugs Never even felt the authects of a strange buzz You never ever catch me holding a beer mug Your talking shit like as if you was a real thug if that's true lick a shot BUCK feel the slug that's what you get for totin guns like you were Elmer Fudd I'm selling tapes for three bones wanna catch a dub? this shit is dope kid it makes you wanna cut the rug Illuminati's got every part of my body bugged the micro chip is in your wrist now give it a tug be nice to females, give a bitch a hug Triple X styles comin cleaner than your tub you better tell your girl about it because she's a scrub A big brow never had a nip in the bud droppin me her seven digits while i'm in the club talkin bout I look I need a back rub son she's a natural disaster like a flash flood i ain't playin dawg you better go test her blood until your positive she's negative don't make no love with or without a glove, you know what i'm speaking of the cub scouts try and jump into the briney shrubs behind the bush turn a back push into a shove what you thinkin tryin bring the underground above? AOI make you cry like a dove,for that shit,for that shit \"\n",
    "# denance = \"[Intro] Last year I was Dr-Drib- dribble down the court Dr-Drib- dribble down the court This year I'm kicking it I'ma kick it for like a motherfucking soccer ball [Verse 1] I'm crazy, I lost my mind I can't find it But that's OK, cause being normal's not a fucking option Cause if it was, then rap wouldn't be my main focus I'd have a 9-to-5, a wife that'll hang my clothes up I'd have a couple kids, a house to call my home, but Something crazy happened, rap became my home, yup! Every since the evidence became so relevant That I was meant to set mics on fire, I've been hesitant But that's over and I'm killing what the hell has sent If you have an issue 'bout who I say I'm better than You can try to write a song, diss me if you ever can But the only thing you got on me is this Eminem (chka chka) It's getting old, we don't share no pens So stop all these dumb accusations and comparisons We ain't nothing alike, we just white So what's the problem between us, that's causing this fight? [Hook] Can I kick it? (Yes, you can!)(x3) Now let me show the whole world that I ain't playing around (x2) [Verse 2] I need a U-Haul to carry this weight I bury the hate, inside of a very big crate Too scary to stay You better be very afraid I carry a cape, I'm Superman, American made You a fairy with a glare and it's gay You compare yourself to the best when you barely can slay I bring urgent care when I rap, don't you get carried away \\\"Son, sit down, get a job\\\", something your parents will say And when I eat MC's, that's really only an errand to me You ain't even half decent, boy/girl, you're half retarded You're like a turtle next to me, I'm an Aston Martin These kids are hopin' to cash out with the rappin' art when They realize 20 years down the road, they haven't started A career, then its clear that you in fact, are garbage So, please sit down or walk yourself inside of coffin Let the pros handle the hustle while you stand there stalking Hating on every move we make, hoping we don't reach stardom [Hook] Can I kick it? (Yes, you can!)(x3) Now let me show the whole world that I ain't playing around (x2)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Blacklist of grabage ngrams (right now specific to 5grams)\n",
    "\n",
    "blacklist = [\n",
    "    'one two three four five',  'two three four five six', 'three four five six seven', 'four five six seven eight', 'five six seven eight nine', 'six seven eight nine ten',\n",
    "    '1 2 3 4 5', '2 3 4 5 6', '3 4 5 6 7', '4 5 6 7 8', '5 6 7 8 9', '6 7 8 9 10', '7 8 9 10 11', '8 9 10 11 12',\n",
    "    '12 11 10 9 8', '11 10 9 8 7', '10 9 8 7 6', '9 8 7 6 5' ,'8 7 6 5 4' ,'7 6 5 4 3' ,'6 5 4 3 2' ,'5 4 3 2 1'\n",
    "    'send corrections typist 1 2',\n",
    "    '1 yo yo yo yo', '2 yo yo yo yo',\n",
    "    'say ho ho say ho', 'ho ho say ho ho', 'uhh uh uh uh uh', 'ya la la la la', 'girl la la la la', 'yo c mon c mon', 'yo uh uh uh uh'\n",
    "    '2x la la la la',\n",
    "    'b c d e f', 'c d e f g', 'd e f g h', 'e f g h j', 'f g h j k', 'g h j k l', 'h j k l m', 'j k l m n', 'k l m n o', 'l m n o p', 'm n o p q', 'n o p q r', 'o p q r s', 'p q r s t', 'q r s t u', 'r s t u v', 's t u v w', 't u v w x', 'u v w x y', 'v w x y z'    \n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# There's probably a library out there that does this, but where's the fun in that?\n",
    "# n=number of words in the cluster,  ly = lyrics to split into ngrams (str)\n",
    "def ngram(n_len, ly):\n",
    "    lst = ly.split()\n",
    "    #We'll make the ngrams by zipping together a series of lists\n",
    "    lists_to_zip = []\n",
    "    lists_to_zip.append(lst)\n",
    "    \n",
    "    \n",
    "    for i in range(n_len-1):\n",
    "        # Each list should have one more padding that the previously cretaed one\n",
    "        new_list = ['*padding*'] + (lists_to_zip[-1])\n",
    "#         print 'NEW LIST ------\\n', new_list\n",
    "        lists_to_zip.append(new_list)\n",
    "#         print 'lists_to_zip --------\\n', lists_to_zip\n",
    "    zipped_lists = zip(*lists_to_zip[::-1])\n",
    "    ngram_list = [' '.join(n) for n in zipped_lists if \"*padding*\" not in n]\n",
    "    ngram_list = [n for n in ngram_list if 'corrections typist' not in n and n not in blacklist and len(set(n.split(' ')))>2] # min 3 unique words\n",
    "    return ngram_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on song 0 of 60086\n",
      "Working on song 1500 of 60086\n",
      "Working on song 3000 of 60086\n",
      "Working on song 4500 of 60086\n",
      "Working on song 6000 of 60086\n",
      "Working on song 7500 of 60086\n",
      "Working on song 9000 of 60086\n",
      "Working on song 10500 of 60086\n",
      "Working on song 12000 of 60086\n",
      "Working on song 13500 of 60086\n",
      "Working on song 15000 of 60086\n",
      "Working on song 16500 of 60086\n",
      "Working on song 18000 of 60086\n",
      "Working on song 19500 of 60086\n",
      "Working on song 21000 of 60086\n",
      "Working on song 22500 of 60086\n",
      "Working on song 24000 of 60086\n"
     ]
    }
   ],
   "source": [
    "# TODO talk to Christopher about borrowing this https://github.com/cing/rapwords/blob/master/RapWordsTalk.ipynb\n",
    "# It's MIT licensed, but it would be nice to reach out\n",
    "from html.parser import HTMLParser\n",
    "\n",
    "class MLStripper(HTMLParser):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        self.strict = False\n",
    "        self.convert_charrefs= True\n",
    "        self.fed = []\n",
    "    def handle_data(self, d):\n",
    "        self.fed.append(d)\n",
    "    def get_data(self):\n",
    "        return ''.join(self.fed)\n",
    "\n",
    "df_data = defaultdict(list)\n",
    "stpwrds = stopwords.words('english')\n",
    "stpwrds = stpwrds + ['chorus', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'x10']\n",
    "song_count = len([name for name in os.listdir('./lyrics')])\n",
    "\n",
    "for i, filename in enumerate(glob.iglob('lyrics/*.txt', recursive=True)):\n",
    "    if i % 1500 == 0:\n",
    "        print('Working on song {} of {}'.format(i, song_count))\n",
    "    with open(filename, 'r') as f:\n",
    "        stripped_lyrics = f.read()\n",
    "        \n",
    "        artist = re.search('Artist:\\s*(.*)\\s*\\n', stripped_lyrics)\n",
    "        song = re.search('Song:\\s*(.*)\\s*\\n', stripped_lyrics)\n",
    "        lyrics = re.search('Typed by:\\s*(.*)\\s*\\n([\\s\\S]*)', stripped_lyrics)\n",
    "\n",
    "        if (artist is not None) and (song is not None) and (lyrics is not None):\n",
    "            artist = artist.group(1)\n",
    "            song = song.group(1)\n",
    "            # Remixes are messing everything out.  Let's filter them out from the start\n",
    "            if ('remix' not in song) and ('Remix' not in song):\n",
    "                lyrics = lyrics.group(2).replace('\\n', ' ')# group(1) is the transcriber\n",
    "                lyrics = re.sub('[^0-9A-Za-z\\s]', ' ', lyrics) # These tokens should be converted to spaces\n",
    "                # The ing --> in mutation will be a shitshow. So long as it's consistent the  \n",
    "                # \"thing\", \"ring\", etc. issues should be negligble with a large enough word group length\n",
    "                lyrics = re.sub('ing ', 'in ', lyrics) \n",
    "                lyrics = re.sub('az ', 'as ', lyrics)\n",
    "                # TODO Take care of the --> da\n",
    "                #      as --> az (nigg)\n",
    "                no_stop = ' '.join([w for w in lyrics.lower().split() if w not in stpwrds])\n",
    "\n",
    "                df_data[\"filename\"].append(filename)\n",
    "                df_data[\"artist\"].append(''.join(re.findall('[a-zA-Z0-9\\s]', artist)))\n",
    "                df_data[\"song\"].append(''.join(re.findall('[a-zA-Z0-9\\s]', song)))\n",
    "                # We can always refer back to the pretty lyrics once we find a match\n",
    "                df_data[\"lyrics\"].append(lyrics)\n",
    "                # We can use the lowercase, punctuation-free, stopword-free for comparison\n",
    "                df_data[\"no_stop\"].append(no_stop)\n",
    "                df_data[\"ngram\"].append(ngram(NGRAM_LEN, no_stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lydf = pd.DataFrame(df_data).sort_values(by='song').reset_index(drop=True)\n",
    "# display(lydf[lydf['song'].duplicated()])\n",
    "display(lydf[lydf['artist'] == 'Dej Loaf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(df_data, open('./processed_songs.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_data = pickle.load(open('./processed_songs.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check the collection of ngrams for intersections\n",
    "# To reduce this to to an O(n^2) problem we create a list of all of the previously seen ngrams\n",
    "# If the one we are looking at has been seen before, record its information\n",
    "# Else add it to the list\n",
    "master_list = dict()\n",
    "\n",
    "def how_similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "song_count = len(df_data['ngram'])\n",
    "for i, song in enumerate(df_data['ngram']): # loop through each song\n",
    "    if i % 100 == 0:\n",
    "        print('Working on song ', i, ' of ', song_count, ' -- Song:', [df_data['song'][i]])\n",
    "    collision_list = dict() # We hold potential collisions here until we can determine if they are a result of a duplicate/remix song\n",
    "    unique_list = dict() # We hold things here for now to avoid comparing a song to itself (repeating chorus, etc.)\n",
    "    for j, n in enumerate(song): # Loop through each ngram\n",
    "        if n not in master_list: # Any repeated ngrams _within_ the song will overwrite the previous one.  This is OK.\n",
    "            unique_list[n] = {'index':i, 'artist': [df_data['artist'][i]], 'song': [df_data['song'][i]], 'no_stop': df_data['no_stop'][i], 'ngram':n, 'count':1}\n",
    "        else:\n",
    "            # Increment the count, append the artist and song to the original\n",
    "            # This approach seems redundant, but I'm not sure how to access the the dict that triggered the else\n",
    "#             print('Found ngram collision! Artists: {} / {}, Song: {} / {}, ngram:{}'.format(master_list[n]['artist'], df_data['artist'][i], master_list[n]['song'], df_data['song'][i], n))\n",
    "            split = n.split(' ')\n",
    "            found_collision = False\n",
    "            #This a colision. But is it relevant?\n",
    "            for k, song in enumerate(master_list[n]['song']):\n",
    "                # The last song we saw with this ngram\n",
    "                saved_no_stop = master_list[n]['no_stop'][-1]\n",
    "                saved_title = master_list[n]['song'][-1]\n",
    "                saved_artist = master_list[n]['artist'][-1]\n",
    "                # TODO do this for the entire song text.  Slow, but we'll see. Maybe use quick sequence matcher?\n",
    "                no_stop_similarity = how_similar(df_data['no_stop'][i], saved_no_stop)\n",
    "                title_similarity = how_similar(df_data['song'][i], saved_title)\n",
    "                artist_similarity = how_similar(df_data['artist'][i], saved_artist)\n",
    "                \n",
    "                \n",
    "                if  (\n",
    "                      df_data['artist'][i] not in saved_artist and # Is one in the other?\n",
    "                      saved_artist not in df_data['artist'][i] and\n",
    "                    # TODO This needs to be generalized for different ngrma lenghts\n",
    "                    # Is the match a repeating (pair of) words? This works better with an even number of ngrams.  \n",
    "                    # This filters 'oooh ahhh's and 'la la la la's\n",
    "                      not (split[0:1] == split[2:3]) and  \n",
    "                      no_stop_similarity < 0.5 and \n",
    "                      title_similarity < 0.5 and \n",
    "                      artist_similarity < 0.5\n",
    "                    ):\n",
    "                        \n",
    "                    collision_list[n] = master_list[n]\n",
    "                    collision_list[n]['artist'].append(df_data['artist'][i])\n",
    "                    collision_list[n]['song'].append(df_data['song'][i])\n",
    "                    collision_list[n]['index'].append(df_data['index'[i]])\n",
    "                    collision_list[n]['count'] += 1\n",
    "                    found_collision = True\n",
    "                    break; # For now we will just record that there is a connection, not all of the connections\n",
    "#                 else:\n",
    "#                     print('Our filter kicked this out! Not saved! Similarity was ', song_similarity)\n",
    "            \n",
    "    if collision_list:\n",
    "         print('Collision(s) found: ', collision_list.keys())\n",
    "    # We have extracted all of the new ngrams, merge it into the master list\n",
    "    master_list = {**master_list, **unique_list, **collision_list}\n",
    "            \n",
    "# TODO --> If a song has more than ... 15? 20? matching ngrams, throw the whole song out.  It's a remix or an alternate version.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle.dump(master_list, open('./matches/matches_list.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master_list = matches_list = pickle.load(open('./matches/matches_list.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "how_similar('1 2 Step Remix Fingazz Version', '1 2 Step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matches = [[x, master_list[x]['artist'], master_list[x]['song']] for x in master_list if len(master_list[x]['artist'])>1]\n",
    "for o in matches:\n",
    "    print(o, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matches_dict = defaultdict(list)\n",
    "for o in matches:\n",
    "    new_key = (', '.join(o[1]))\n",
    "    matches_dict[new_key] = o\n",
    "    \n",
    "print(len(matches_dict))\n",
    "\n",
    "for m in matches_dict:\n",
    "    print(matches_dict[m], '\\n')\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(matches))\n",
    "print(len(matches_dict))\n",
    "\n",
    "with open('matches/raw_matches.txt', 'w+') as output:\n",
    "    for o in matches:\n",
    "        output.write(str(o) + '\\n')\n",
    "\n",
    "with open('matches/by_artist_matches.txt', 'w+') as output:\n",
    "    for m in matches_dict:\n",
    "        output.write(str(matches_dict[m][0]) + '\\n')#+ ' --> ' + str(matches_dict[m]) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ['wa da da dang wa da da da dang', ['Brother Ali', 'Cormega f Big Daddy Kane Grand Puba Kool DJ Red Alert KRSOne Parrish Smith'], ['Nine Double Em', 'Fresh']] \n",
    "    ['got clean underwear somebody say oh yeah oh yeah', ['Boot Camp Clik', 'Afroman'], ['Down by Law', 'Dopefiend']] \n",
    "\n",
    "##TODO\n",
    "1. ~~If one artist's name is in another's, throw out the match~~\n",
    "1. Currently checking if an ngram has 3 identical 2-word groups. Bellow is ideal\n",
    "1. If an ngram repeats same phrase more than len(ngram)/2 times, throw it out\n",
    "1. ~~Checked for number words in ngram. This doesn't take into account unique patterns of two words.  Try again for the previous goal~~\n",
    "1. ~~Lower ngram length.  With stopwords removed, 8 is too hight.~~\n",
    "1. 6 is still too high \"Yay though I walk through the Shadow of Death\" comes up 34 times but is too short. Don't underestimate the stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For each song, generate a dict of ngrams where x < n > y\n",
    "def dict_ngram(lyrics, rng=None):\n",
    "    res = {}\n",
    "    for i in range (*rng):\n",
    "        res[i] = ngram(i, lyrics)\n",
    "    return res\n",
    "    \n",
    "# print(dict_ngram(tribe, rng=(3, 8) ))\n",
    "# print(dict_ngram(sage, rng=(3, 8) ))\n",
    "tribe_dict = dict_ngram(tribe, rng=(2, 8) )\n",
    "sage_dict = dict_ngram(sage, rng=(2, 8) )\n",
    "\n",
    "print(tribe_dict)\n",
    "# TODO We if we are doing this with multiple lenght ngrams,\n",
    "# we don't want shorter ones that are a subset of the longer ones.\n",
    "# Find a way to only keep the longest ngram\n",
    "# def longest_ngram (dict_x, dict_y, rng)\n",
    "#     rng = reversed(rng)\n",
    "#     for i in rng:\n",
    "#         print(i, set(tribe_dict[i]).intersection(sage_dict[i]))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Testing out the graphing library\n",
    "G = nx.Graph()\n",
    "           \n",
    "edges = []\n",
    "for i in range (2,8):\n",
    "    n = (set(tribe_dict[i]).intersection(sage_dict[i]))\n",
    "    for edg in n:\n",
    "        print('Edge for {}gram'.format(i), edg)\n",
    "        edges.append(' '.join(edg))\n",
    "        \n",
    "print('All edges \\n', edges)\n",
    "for edg in edges:\n",
    "#     G.add_edge('tribe', 'sage')\n",
    "    G.add_edge('tribe', 'sage', lyric=' '.join(edg))\n",
    "    \n",
    "import matplotlib.pyplot as plt    \n",
    "%matplotlib inline\n",
    "nx.draw(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
